{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWCyZCunTZL"
      },
      "source": [
        "# 한국어 데이터로 챗봇 만들기!!!\n",
        "\n",
        "이제까지 영어로 만들었던 챗봇을 이번에는 한국어 데이터로 바꾸는 실전 프로젝트를 하게 되었다!!!\n",
        "\n",
        "우선 주요 라이브러리 버전부터 확인~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlcGSNJ8nL_k",
        "outputId": "1fcfd6fe-8b9a-4e55-ec4e-d62679889344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgwqxgEFntdS"
      },
      "source": [
        "# Step 1. 데이터 수집하기!!\n",
        "\n",
        "한국어 챗봇 데이터는 송영숙님께서 공개한 챗봇 데이터를 사용한다.\n",
        "\n",
        "이 데이터는 아래의 링크에서 다운 가능하다.\n",
        "\n",
        "데이터셋 다운로드 링크 : https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv\n",
        "\n",
        "주피터 노트북에서 할려면 cloud shell에서 아래 명령어를 입력하면 된다!!\n",
        "\n",
        "```\n",
        "$ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
        "$ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/\n",
        "```\n",
        "\n",
        "참고로 전 코랩에서 할 것이라서 해당 명령어를 통해 클라우드 주퍼터에 옮겨진 데이터를 다운받아 코랩 연동을 통해 코랩으로 불러올 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3LYvMWdnkVS",
        "outputId": "ae962b44-000d-42a1-b4fe-516d69714c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "mmiOlJeYpHCu",
        "outputId": "f03c9704-f712-4298-cc30-216e50317d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11823, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Q                   A  label\n",
              "0                   12시 땡!          하루가 또 가네요.      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다.      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n",
              "4                  PPL 심하네          눈살이 찌푸려지죠.      0\n",
              "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n",
              "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n",
              "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n",
              "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n",
              "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc09bde7-7470-40a1-a541-afc7b088df5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SD카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SD카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
              "      <td>잘 모르고 있을 수도 있어요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc09bde7-7470-40a1-a541-afc7b088df5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc09bde7-7470-40a1-a541-afc7b088df5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc09bde7-7470-40a1-a541-afc7b088df5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "data_path = '/content/drive/MyDrive/AIFFEL/DATASET/Ex14/ChatbotData.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "print(data.shape)\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0NykKbdugFd"
      },
      "source": [
        "# Step 2. 데이터 전처리하기\n",
        "\n",
        "영어 데이터와는 전혀 다른 데이터라서 영어 데이터에 사용했던 전처리와 일부 동일한 전처리를 거친 후 또 다른 전처리를 거쳐야만 한다. 우선 결측치부터 확인~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr1DaqDhrcH8",
        "outputId": "12b043cf-46f0-4ed8-fa47-60eafa8b7640"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Q        0\n",
              "A        0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjOry5yjy0nX"
      },
      "source": [
        "결측치는 없는 걸로 판명났고, 이제 **구두점(punctuation)**을 제거하는 **정규 표현식(Regular Expression)**을 사용한다. 단어를 토크나이징(tokenizing)을 하는 데 방해가 되지 않도록 정제하는 것이 목표라는 점~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "0IhdU8h0yznj"
      },
      "outputs": [],
      "source": [
        "# 전처리 함수\n",
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()\n",
        "\n",
        "  # 단어와 구두점(punctuation) 사이에 거리를 만든다.\n",
        "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이~~\n",
        "  # 즉, student와 온점 사이에 거리를 만들어 떼어 놓는다.\n",
        "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "  \n",
        "  # 구두점을 제외한 나머지 특수문자들은 공백인 ' '로 대체한다.\n",
        "  # 한글 자모음으로 만들 수 있는 모든 문자, 숫자, 알파벳, 구두점은 살린다.\n",
        "  sentence = re.sub(r\"[^0-9a-zA-Z가-힣?.!,]+\", \" \", sentence)\n",
        "  sentence = sentence.strip()\n",
        "  return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "uQHgjuOL0yB8"
      },
      "outputs": [],
      "source": [
        "data['Q'] = data['Q'].apply(lambda x : preprocess_sentence(x))\n",
        "data['A'] = data['A'].apply(lambda x : preprocess_sentence(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "uECERmeL1oA5",
        "outputId": "50da020b-bda9-4993-e07b-b2a703c9af57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Q                    A  label\n",
              "0                  12시 땡 !          하루가 또 가네요 .      0\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다 .      0\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠 .      0\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠 .      0\n",
              "4                  ppl 심하네          눈살이 찌푸려지죠 .      0\n",
              "5                sd카드 망가졌어  다시 새로 사는 게 마음 편해요 .      0\n",
              "6                  sd카드 안돼  다시 새로 사는 게 마음 편해요 .      0\n",
              "7             sns 맞팔 왜 안하지    잘 모르고 있을 수도 있어요 .      0\n",
              "8  sns 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요 .      0\n",
              "9        sns 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요 .      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d70304f-5e42-4aef-a691-450314ffed01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡 !</td>\n",
              "      <td>하루가 또 가네요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ppl 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sd카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sd카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sns 맞팔 왜 안하지</td>\n",
              "      <td>잘 모르고 있을 수도 있어요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sns 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sns 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요 .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d70304f-5e42-4aef-a691-450314ffed01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d70304f-5e42-4aef-a691-450314ffed01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d70304f-5e42-4aef-a691-450314ffed01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHYvKgCv3p-E"
      },
      "source": [
        "단, 실험적인 측면에서 알파벳과 숫자는 조금 살려봤다.\n",
        "실험을 해서 에러가 뜬다면 그 부분에 대한 전처리는 따로 해 보겠다.\n",
        "\n",
        "전처리는 잘 된 것을 확인할 수 있었다. 저는 Q와 A만을 남겨도 무방하다고 판단하여 라벨은 drop하기로 했다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EYQzOEhL1qau",
        "outputId": "65edf48d-c984-422b-b6c4-2ec311ca0c51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         Q                    A\n",
              "0                  12시 땡 !          하루가 또 가네요 .\n",
              "1              1지망 학교 떨어졌어           위로해 드립니다 .\n",
              "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠 .\n",
              "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠 .\n",
              "4                  ppl 심하네          눈살이 찌푸려지죠 .\n",
              "5                sd카드 망가졌어  다시 새로 사는 게 마음 편해요 .\n",
              "6                  sd카드 안돼  다시 새로 사는 게 마음 편해요 .\n",
              "7             sns 맞팔 왜 안하지    잘 모르고 있을 수도 있어요 .\n",
              "8  sns 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요 .\n",
              "9        sns 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요 ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8cd36ab-f499-4ae8-b3ba-5f8dcb6ab6a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡 !</td>\n",
              "      <td>하루가 또 가네요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ppl 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sd카드 망가졌어</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sd카드 안돼</td>\n",
              "      <td>다시 새로 사는 게 마음 편해요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sns 맞팔 왜 안하지</td>\n",
              "      <td>잘 모르고 있을 수도 있어요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sns 시간낭비인 거 아는데 매일 하는 중</td>\n",
              "      <td>시간을 정하고 해보세요 .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sns 시간낭비인데 자꾸 보게됨</td>\n",
              "      <td>시간을 정하고 해보세요 .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8cd36ab-f499-4ae8-b3ba-5f8dcb6ab6a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8cd36ab-f499-4ae8-b3ba-5f8dcb6ab6a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8cd36ab-f499-4ae8-b3ba-5f8dcb6ab6a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "data.drop('label', axis=1, inplace=True)\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "YtQ3VKPP6l4z"
      },
      "outputs": [],
      "source": [
        "# 질문, 답변 리스트 생성\n",
        "questions = list(data['Q'])\n",
        "answers = list(data['A'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCBiJu6U6sFG"
      },
      "source": [
        "# Step 3. SubwordTextEncoder 사용\n",
        "\n",
        "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있다만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용하게 될 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRefF39GpTiv"
      },
      "source": [
        "## (1) 단어 집합 형성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "JnvgyX1R6rKn"
      },
      "outputs": [],
      "source": [
        "# 질문과 답변 데이터에 대해 Vocabulary 생성\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF_Z94J0rdkk",
        "outputId": "d2c4c276-f080-481c-9979-365f832d896c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' .', ' ?', '거예요', '수_', '게_', '너무_', '더_', '거_', '좋아하는_', '는_', '이_', ' . ', '을_', '잘_', '도_', '고_', '요', '것_', '많이_', '안_']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.subwords[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTT6S6S7oZdi"
      },
      "source": [
        "`tokenizer.subwords`를 통해 토큰화된 서브워드를 확인했고, 원래 문장과 정수 인코딩 진행한 결과를 확인해 볼 수 있었다.\n",
        "\n",
        "단어 집합을 생성하고 보니, seq2seq 챕터에서 배웠던 것처럼 인코더-디코더 모델 계열에는 디코더의 입력으로 사용할 시작을 의미하는 시작 토큰 SOS와 종료 토큰 EOS 또한 존재한다. 해당 토큰들도 단어 집합에 포함시킬 필요가 있기 때문에 이 두 토큰에 정수값을 부여해 준다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "DvMFqlTlmpLN"
      },
      "outputs": [],
      "source": [
        "# 시작 토큰과 종료 토큰에 대한 정수 부여.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size],[tokenizer.vocab_size + 1]\n",
        "\n",
        "# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 +2로 늘려줌\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwaVmW4Nnuv4"
      },
      "source": [
        "시작 토큰과 종료 토큰을 추가해 주었으나, 단어 집합의 크기도 +2로 해준다.  \n",
        "시작 토큰의 번호와 종료 토큰의 번호, 그리고 단어 집합의 크기도 출력해서 확인해본다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gIyoX8XmpOo",
        "outputId": "09574a76-5210-4e88-9dde-283eb4de80ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시작 토큰 번호 : [8162]\n",
            "종료 토큰 번호 : [8163]\n",
            "단어 집합의 크기 : 8164\n"
          ]
        }
      ],
      "source": [
        "print('시작 토큰 번호 :',START_TOKEN)\n",
        "print('종료 토큰 번호 :',END_TOKEN)\n",
        "print('단어 집합의 크기 :',VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxwC965hpGBX"
      },
      "source": [
        "## (2) 정수 인코딩과 패딩\n",
        "\n",
        "단어 집합을 생성한 후 SubwordTextEncoder의 토크나이저로 정수 인코딩을 진행할 수 있다. 이는 토크나이저의 `encode()`를 사용하면 된다. 우선 임의로 선택한 20번 질문의 샘플, 즉 `questions[20]`을 가지고 정수 인코딩을 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69mHY9FC9Nvn",
        "outputId": "7531d8b8-dc71-4daa-ab34-9d14cca73502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "임의의 질문 샘플을 정수 인코딩 : [7861, 1715, 319, 4878]\n"
          ]
        }
      ],
      "source": [
        "# SubwordTextEncoder 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환\n",
        "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[40])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEhj7u8usIpM"
      },
      "source": [
        "임의의 질문 문장이 정수 시퀀스로 변한이 되었다. 반대로 정수 인코딩 된 결과는 다시 `decode()`를 사용해 기존의 텍스트 시퀀스로 복원할 수 있다. 40번 질문 샘플을 가지고 정수 인코딩하고, 다시 이를 디코딩하는 과정은 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em5wYp94rahR",
        "outputId": "197acd09-3db3-4c05-a81d-3df445db3466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 후의 문장 [7861, 1715, 319, 4878]\n",
            "기존 문장: 간만에 떨리니까 좋더라\n"
          ]
        }
      ],
      "source": [
        "# 서브워드텍스트인코더 토크나이저의 .encode()와 .decode() 테스트해보기\n",
        "# 임의의 입력 문장을 sample_string에 저장\n",
        "sample_string = questions[40]\n",
        "\n",
        "# encode() : 텍스트 시퀀스 --> 정수 시퀀스\n",
        "tokenized_string = tokenizer.encode(sample_string)\n",
        "print ('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
        "\n",
        "# decode() : 정수 시퀀스 --> 텍스트 시퀀스\n",
        "original_string = tokenizer.decode(tokenized_string)\n",
        "print ('기존 문장: {}'.format(original_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aqc6ufqRsl_8"
      },
      "source": [
        "정수 인코딩된 문장을 `decode()`를 하면 자동으로 서브워드들까지 다시 붙여서 기존 단어로 복원해 준다. 가령, 정수 인코딩 문장을 보면 정수가 4개인데 기존 문장의 띄어쓰기 단위인 어절은 3개밖에 존재하지 않는다. 이는 한 어절이 정수 인코딩 후에는 두 개 이상의 정수일 수 있다는 것을 의미한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsFDIiyLsdq0",
        "outputId": "b8adfa35-1070-4295-c2ce-a43fb8ab4ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7861 ----> 간만에 \n",
            "1715 ----> 떨리\n",
            "319 ----> 니까 \n",
            "4878 ----> 좋더라\n"
          ]
        }
      ],
      "source": [
        "# 각 정수는 각 단어와 어떻게 mapping되는지 병렬로 출력\n",
        "# 서브워드텍스트인코더는 의미있는 단위의 서브워드로 토크나이징한다. 띄어쓰기 단위 X 형태소 분석 단위 X\n",
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer.decode([ts])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X28NU5mmtcxJ"
      },
      "source": [
        "실제로 '떨리니까'라는 한 어절이 1715, 319라는 두 개의 정수로 인코딩이 되어 있는 걸 확인할 수 있었다. 이렇게 샘플 하나에 대해 정수 인코딩과 디코딩을 해 봐서 그 결과를 확인해 봤으면, 이번에는 전체 데이터에 대해서도 인코딩과 디코딩을 해 주어야 하겠죠?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpCrtAnXugL0"
      },
      "source": [
        "이를 위한 함수로 tokenize_and_filter()를 사용할 것이다. \n",
        "그리고 최대 패딩 길이를 정하기 전에 해당 데이터셋의 질문 문장 답변 문장의 최대 길이를 각각 구해보고 개략적으로 패딩 길이를 정하기로 했다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdM72bVnu_xT",
        "outputId": "cfd8556e-2e92-4d48-8b05-e92d337a5446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문의 최대 길이 : 57 \n",
            "답변 최대 길이 : 78\n"
          ]
        }
      ],
      "source": [
        "# 질문 데이터 길이\n",
        "q_word_len = [len(x) for x in questions]\n",
        "\n",
        "# 답변 데이터 길이\n",
        "a_word_len = [len(x) for x in answers]\n",
        "\n",
        "# 질문과 답변의 최대 길이를 각각 뽑아보기\n",
        "print(f'질문의 최대 길이 : {max(q_word_len)} \\n답변 최대 길이 : {max(a_word_len)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uLZfcvjvqO5"
      },
      "source": [
        "질문의 최대 길이와 답변의 최대 길이를 보고 대강 패딩 길이를 얼추 60 정도로 맞추면 될 거 같다!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "-GK2LBuAsc9u"
      },
      "outputs": [],
      "source": [
        "# 최대 길이를 60으로 정의\n",
        "MAX_LENGTH = 60\n",
        "\n",
        "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    tokenized_inputs.append(sentence1)\n",
        "    tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "  return tokenized_inputs, tokenized_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "Mp3HmjU2v_n2"
      },
      "outputs": [],
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7raChN1twDN_"
      },
      "source": [
        "정수 인코딩과 패딩이 진행된 후의 데이터 크기를 확인해 보면!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6OVWBq8wCID",
        "outputId": "b6aaf621-0593-45e8-e4a4-0fcea40f9a0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문 데이터의 크기(shape) : (11823, 60)\n",
            "답변 데이터의 크기(shape) : (11823, 60)\n"
          ]
        }
      ],
      "source": [
        "print('질문 데이터의 크기(shape) :', questions.shape)\n",
        "print('답변 데이터의 크기(shape) :', answers.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXlsBfVywVWB"
      },
      "source": [
        "이상없이 모든 문장의 최대 길이는 60으로 고정되었음을 알 수 있다!!!\n",
        "\n",
        "설정한 최대 문장 길이보다 짧은 문장들은 0으로 채움으로써 패딩이 되었을 것이고, 반대로 긴 문장들은 뒷부분을 짤려나갔을 것이다!!!\n",
        "\n",
        "임의로 100번 샘플을 출력해 보면~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG9jFB6uwTwk",
        "outputId": "1abc219e-0a3e-416b-f014-aed80cb340ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8162 1939  459 8163    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "[8162  500 6963 7938  689 2446   49 8163    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "# 100번 샘플을 임의로 출력\n",
        "print(questions[100])\n",
        "print(answers[100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4CzqaJhyH6x"
      },
      "source": [
        "다음으로, 질문과 답변의 쌍을 `tf.data.Dataset` API의 입력으로 사용하여 파이프라인을 구성한다. 이 때 교사 강요를 위해서 `answer[:,:-1]`디코더의 입력값, `answer[:,1:]`을 디코더의 레이블로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "3jyJ1eP0w3zk"
      },
      "outputs": [],
      "source": [
        "# 텐서플로우 dataset을 이용해 shuffle을 수행하되, 배치 크기로 데이터를 묶는다.\n",
        "# 또한 이 과정에서 교사 강요를 사용하기 위해 디코더의 입력과 실제값 시퀀스를 구성한다.\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 11823\n",
        "\n",
        "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {'inputs' : questions,\n",
        "     'dec_inputs' : answers[:,:-1]},   # 디코더의 입력. 마지막 패딩 토큰 제거\n",
        "     {'outputs': answers[:, 1:]},        # 맨 처음 토큰(시작 토큰) 제거.    \n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SEZZWyi0SOJ",
        "outputId": "8a677347-bb5b-42d1-fa67-3961333051ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8162 3837   74 7880    1 8163    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n",
            "[[8162 3837   74 7880    1 8163    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]]\n",
            "[[3837   74 7880    1 8163    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "# 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지를 확인\n",
        "print(answers[0])    # 기존 샘플\n",
        "print(answers[:1][:, :-1])   # 마지막 패딩 토큰이 제거되면서 길이가 59로 바뀜\n",
        "print(answers[:1][:, 1:])    # 맨 처음 토큰(시작 토큰) 제거되면서 역시 길이가 59로 바뀜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpY0PYUw1hOL"
      },
      "source": [
        "# Step 4. 모델 구성하기\n",
        "\n",
        "이제 트랜스포머를 본격적으로 만드는 시간이다!! 지금까지 밟아왔던 과정을 토대로 진행하면 된다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj5Bvtxf5rdf"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icv9_QXC5qG_"
      },
      "source": [
        "## (1) 포지셔널 인코딩 레이어\n",
        "먼저 포지셔널 인코딩 레이어부터 짠다.  \n",
        "\n",
        "많은 자연어 처리 모델들은 텍스트 문장을 입력으로 받기 위해 단어를 임베딩 벡터로 변환하는 벡터화 과정을 거친다. 트랜스포머 또한 그 점에서 다른 모델들과 크게 다르지 않다. 하지만 트랜스포머 모델의 입력 데이터 처리에는 RNN 계열의 모델들과 다른 점이 있는데, 바로 임베딩 벡터에 어떤 값을 더해준 뒤에 입력으로 사용한다는 점이다. 그 값은 바로 위 그림에서의 포지셔널 인코딩에 해당하는 부분이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ZcyP0Q5x0V"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tiz-08a5y4g"
      },
      "source": [
        "이렇게 해주는 이유는 트랜스포머는 입력을 받을 때, 문장에 있는 단어들을 1개씩 순차적으로 받는 것이 아니라, 문장에 있는 모든 단어를 한꺼번에 입력으로 받기 때문에 트랜스포머가 RNN과 결정적으로 다른 점이라고 할 수 있다. RNN에는 어차피 문장을 구성하는 단어들이 어순대로 모델에 입력되므로, 모델에게 따로 어순을 알려줄 필요가 없다. 그러나 문장에 있는 모든 단어를 한꺼번에 문장 단위로 입력받는 트랜스포머는 자칫 'I ate lunch'와 'lunch ast I'를 구분할 수 없을 수도 있다. 그래서 같은 단어라도 그 단어가 문장의 몇 번째 어순으로 입력되었는지를 모델에 추가로 알려 주기 위해, 단어의 임베딩 벡터에다가 위치 정보를 가진 벡터값을 더해서 모델의 입력으로 삼는 것이다!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "n8GJiuRq1F7e"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    # 각도 배열 생성\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    # sin과 cosine이 교차되도록 재배열\n",
        "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
        "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
        "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
        "\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMq_P3qU5VwD"
      },
      "source": [
        "## (2) 어텐션? 어텐션!\n",
        "트랜스포머 인코더와 디코더에서 사용하고 있는 개념인 어텐션에 대해 알아보자!\n",
        "\n",
        "어텐션이란?\n",
        "어텐션 메컨즘을 그림으로 표현한다면 아래와 같이 표현할 수 있을 거 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHlZ25Zk56W-"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRBN7iHZ57_z"
      },
      "source": [
        "어텐션 함수는 주어진 쿼리에 대해서 모든 키와의 유사도를 각각 구한다. 그리고 구해낸 이 유사도를 키와 맵핑되어 있는 각각의 값에 반영해준다. 그리고 유사도가 반영된 값을 모두 더해 뭉쳐주면 이게 최종 결과인 어텐션 값이 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p89slE1l6Qw5"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvB9qQFs6RzM"
      },
      "source": [
        "* 첫 번째 그림 : 인코더 셀프 어텐션은 인코더에서 이루어짐을 나타냄.\n",
        "* 두 번째 그림 : 디코더 셀프 어텐션은 디코더에서 이루어짐을 나타냄.\n",
        "* 세 번째 그림 : 인코더-디코더 어텐션 역시 디코더에서 이루어짐을 나타냄."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "nAsRmGp46inL"
      },
      "outputs": [],
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # 가중치를 정규화\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # 패딩에 마스크 추가\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax적용\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "jQLk1JJM6ipU"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # Q, K, V에 각각 Dense를 적용합니다\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKLpXLi17MaO"
      },
      "source": [
        "# (3) 마스킹\n",
        "\n",
        "두 정수 시퀀스에 대해서 각각 결과가 출력될텐데, 오직 숫자가 0인 위치에서만 숫자 1이 나오고, 숫자 0이 아닌 위치에서는 숫자 0인 벡터를 출력한다. 어텐션 연산 시에 패딩 마스킹을 참고하면 불필요하게 숫자 0을 참고하지 않게 할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTE7QS5Z6irh",
        "outputId": "317261a5-ef68-491d-922b-c4db6c13f53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imgFT7CP6yOz"
      },
      "source": [
        "트랜스포머의 경우, 전체 문장이 문장 행렬로 들어가기 때문에 위치와 상관없이 모든 단어를 참고해서 다음 단어를 예측할 수 있다. 하지만 사실 우리가 원하는 것은 이전 단어들로부터 다음 단어를 예측하는 훈련을 제대로 하는 것이다. 따라서 이러한 문제를 해결하기 위해 자신보다 다음에 나올 단어를 참고하지 않도록 가리는 기법이 룩 어헤드 마스킹 기법이다.\n",
        "\n",
        "이 기법은 어텐션을 수행할 때, Query 단어 뒤에 나오는 Key 단어들에 대해서는 마스킹 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x63E9I0p6iwR",
        "outputId": "6bad1772-181a-46b4-f628-b96927304b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhfRWb3R8CEY"
      },
      "source": [
        "## (4) 인코더 설계\n",
        "\n",
        "트랜스포머의 입력, 그리고 트랜스포머 내부에서 일어나는 어텐션에 대해서도 정리했으니, 이제는 인코더 층을 구현할 차례이다.\n",
        "\n",
        "하나의 인코더 층은 크게 두 개의 서브 층(sublayer)으로 나뉜다. 바로 셀프 어텐션과 피드 포워드 신경망이다. 셀프 어텐션은 멀티 헤드 어텐션으로 병렬적으로 이루어진다.\n",
        "\n",
        "두 개의 서브 층을 가지는 하나의 인코더 층을 구현하는 함수를 구현해보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "F3mOSArY6iyq"
      },
      "outputs": [],
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-0bOPM78gK6"
      },
      "source": [
        "### 인코더 층을 쌓아 인코더 만들기\n",
        "\n",
        "이렇게 구현한 인코더 층을 임베딩 층과 포지셔널 인코딩을 연결하고 사용자가 원하는 만큼의 인코더 층을 쌓음으로써 트랜스포머의 인코더를 완성할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "eo0awPl-6i1O"
      },
      "outputs": [],
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "  # 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yom-FUZC9uUn"
      },
      "source": [
        "## (5) 디코더 설계\n",
        "\n",
        "디코더는 인코더와 비슷하지만, 인코더보다 조금 더 복잡하다. 인코더는 두 개의 서브 층으로 구성되지만 디코더는 세 개의 서브 층으로 구성된다.(하나의 서브 층이 더 추가됨)\n",
        "\n",
        "첫 번째는 **셀프 어텐션**, 두 번째는 **인코더-디코더 어텐션**, 세 번째는 **피드 포워드 신경망**이다. 특히 인코더-디코더 어텐션의 경우 셀프 어텐션과는 달리 Query가 디코더의 벡터인 반면에 Key와 Value가 인코더의 벡터라는 특징이 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "feM-oAJ-9low"
      },
      "outputs": [],
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFmrvhVL-U3m"
      },
      "source": [
        "### 디코더 층을 쌓아 디코더 만들기\n",
        "\n",
        "이렇게 구현한 디코더의 층은 임베딩 층과 포지셔널 인코딩을 연결하고, 사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성된다. 인코더와 마찬가지로 num_layers 개수의 디코더 층을 쌓는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "CZFGM1kS3aW-"
      },
      "outputs": [],
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "  # 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ3hlMiGAq8P"
      },
      "source": [
        "# (6) 모델 정의 및 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "rf2juLCU3cat"
      },
      "outputs": [],
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  # 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-jueL9c2xzQ"
      },
      "source": [
        "## (7) 모델 생성\n",
        "\n",
        "하이퍼 파라미터를 조정해 실제 논문의 트랜스포머보다는 작은 모델을 만들 것이다.\n",
        "\n",
        "여기서 설정한 주요 하이퍼파라미터는 다음과 같다.   \n",
        "* D_MODEL : 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "* NUM_LAYERS : 인코더와 디코더 층의 개수\n",
        "* NUM_HEADS : 멀티 헤드 어텐션에서의 헤드 수\n",
        "* UNITS : 피드 포워드 신경망의 은닉층의 크기\n",
        "* DROPOUT : 드롭아웃 하고자 하는 비율"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO5xOV-RBID9",
        "outputId": "76c340c2-70f9-42ed-8073-016038b1b5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " inputs (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    2881536     ['inputs[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3408896     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8164)   2098148     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,388,580\n",
            "Trainable params: 8,388,580\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "D_MODEL = 256\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 8\n",
        "UNITS = 256\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    d_model=D_MODEL,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_heads=NUM_HEADS,\n",
        "    units=UNITS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-opQRoZRD27L"
      },
      "source": [
        "### 손실 함수\n",
        "\n",
        "레이블인 시퀀스에 패딩이 있으므로, loss를 계산할 때 패딩 마스크를 적용할 것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "ZBicPv_hDuYO"
      },
      "outputs": [],
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoixHITSEA4S"
      },
      "source": [
        "### 커스텀된 학습률\n",
        "\n",
        "모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮춰 가면서 안정적으로 수렴하게 되는 고급 기법을 널리 사용하고 있는데, 이런 방법을 커스텀 학습률 스케줄링(Custom Learning Scheduling)이라고 한다.\n",
        "\n",
        "논문에 나와있는 공식을 토대로 커스텀 학습률 스케줄러를 적용한다. 아담 옵티마이저를 채택했다.\n",
        "\n",
        "$lrate = d_{model}^{-0.5}⋅min(step\\_num^{-0.5},step\\_num⋅warmup\\_steps^{-1.5})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "FJRRLO7vDuf-"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhfZP1XQEtW1"
      },
      "source": [
        "### 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "PCNbBW3OEn-F"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH -1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjASxb7rEoFI",
        "outputId": "5e181f7e-2b6d-446f-9f2e-3160266e83ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "185/185 [==============================] - 20s 69ms/step - loss: 0.9660 - accuracy: 0.0155\n",
            "Epoch 2/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.7828 - accuracy: 0.0326\n",
            "Epoch 3/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.6673 - accuracy: 0.0333\n",
            "Epoch 4/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.6154 - accuracy: 0.0357\n",
            "Epoch 5/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.5763 - accuracy: 0.0381\n",
            "Epoch 6/50\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.5365 - accuracy: 0.0408\n",
            "Epoch 7/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.4933 - accuracy: 0.0446\n",
            "Epoch 8/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.4454 - accuracy: 0.0498\n",
            "Epoch 9/50\n",
            "185/185 [==============================] - 14s 73ms/step - loss: 0.3932 - accuracy: 0.0554\n",
            "Epoch 10/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.3386 - accuracy: 0.0618\n",
            "Epoch 11/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.2842 - accuracy: 0.0683\n",
            "Epoch 12/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.2305 - accuracy: 0.0757\n",
            "Epoch 13/50\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.1809 - accuracy: 0.0830\n",
            "Epoch 14/50\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.1378 - accuracy: 0.0896\n",
            "Epoch 15/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.1014 - accuracy: 0.0959\n",
            "Epoch 16/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0728 - accuracy: 0.1011\n",
            "Epoch 17/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0530 - accuracy: 0.1049\n",
            "Epoch 18/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0401 - accuracy: 0.1071\n",
            "Epoch 19/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0333 - accuracy: 0.1082\n",
            "Epoch 20/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0292 - accuracy: 0.1088\n",
            "Epoch 21/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0275 - accuracy: 0.1091\n",
            "Epoch 22/50\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.0262 - accuracy: 0.1093\n",
            "Epoch 23/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0237 - accuracy: 0.1098\n",
            "Epoch 24/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0205 - accuracy: 0.1106\n",
            "Epoch 25/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0179 - accuracy: 0.1112\n",
            "Epoch 26/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0162 - accuracy: 0.1117\n",
            "Epoch 27/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0144 - accuracy: 0.1122\n",
            "Epoch 28/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0130 - accuracy: 0.1125\n",
            "Epoch 29/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0119 - accuracy: 0.1127\n",
            "Epoch 30/50\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0107 - accuracy: 0.1130\n",
            "Epoch 31/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0101 - accuracy: 0.1132\n",
            "Epoch 32/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0094 - accuracy: 0.1134\n",
            "Epoch 33/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0086 - accuracy: 0.1136\n",
            "Epoch 34/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0081 - accuracy: 0.1137\n",
            "Epoch 35/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0073 - accuracy: 0.1139\n",
            "Epoch 36/50\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.0070 - accuracy: 0.1140\n",
            "Epoch 37/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0066 - accuracy: 0.1141\n",
            "Epoch 38/50\n",
            "185/185 [==============================] - 13s 70ms/step - loss: 0.0063 - accuracy: 0.1142\n",
            "Epoch 39/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0060 - accuracy: 0.1143\n",
            "Epoch 40/50\n",
            "185/185 [==============================] - 13s 72ms/step - loss: 0.0056 - accuracy: 0.1143\n",
            "Epoch 41/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0055 - accuracy: 0.1144\n",
            "Epoch 42/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0051 - accuracy: 0.1145\n",
            "Epoch 43/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0050 - accuracy: 0.1145\n",
            "Epoch 44/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0045 - accuracy: 0.1146\n",
            "Epoch 45/50\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0046 - accuracy: 0.1146\n",
            "Epoch 46/50\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0042 - accuracy: 0.1147\n",
            "Epoch 47/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0041 - accuracy: 0.1146\n",
            "Epoch 48/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0040 - accuracy: 0.1147\n",
            "Epoch 49/50\n",
            "185/185 [==============================] - 13s 71ms/step - loss: 0.0036 - accuracy: 0.1149\n",
            "Epoch 50/50\n",
            "185/185 [==============================] - 13s 69ms/step - loss: 0.0036 - accuracy: 0.1148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4c194e79d0>"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmrGFB6zFbTt"
      },
      "source": [
        "# Step 5. 모델 평가하기!\n",
        "\n",
        "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만드는 과정이다.  \n",
        "예측 단계는 기본적으로 다음과 같은 과정을 거친다!!\n",
        "\n",
        "* 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
        "\n",
        "* 입력 문장을 토크나이징하고,` START_TOKE N`과 `END_TOKEN`을 추가한다.\n",
        "\n",
        "* 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
        "\n",
        "* 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
        "\n",
        "* 디코더는 예측된 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
        "\n",
        "* `END_TOKEN`이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "BOECn00rGDoD"
      },
      "outputs": [],
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30   5 1059   7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "  \n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수\n",
        "  # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복한다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가된다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 된다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgYv0VWWGJbb"
      },
      "source": [
        "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수도 만들어 준다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "rZhuub0RGLoP"
      },
      "outputs": [],
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEcm0ZumGJl7"
      },
      "source": [
        "임의의 문장으로부터 챗봇의 대답을 얻어보면~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "9jXK2B0GGIHd",
        "outputId": "436ede6d-106a-49a9-ebda-b71ed1db0cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 식사 맛있게 하세요!\n",
            "출력 : 저는 생각보다 많아요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'저는 생각보다 많아요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "sentence_generation('식사 맛있게 하세요!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "RP7DOmXBGRgh",
        "outputId": "f8da2c16-f4c8-4fe5-ff31-243120e8190a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 취미가 뭐예요?\n",
            "출력 : 그래도 상관없어요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'그래도 상관없어요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "sentence_generation('취미가 뭐예요?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "kBWe64fsGbsd",
        "outputId": "f4e39618-8a88-4a8e-c4e9-9197d6ab8256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘은 왜 결석했나요?\n",
            "출력 : 건 그럴 거예요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'건 그럴 거예요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 179
        }
      ],
      "source": [
        "sentence_generation('오늘은 왜 결석했나요?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "WaKQ2iZFGRrV",
        "outputId": "73dfb6d8-d6ea-4a72-c75d-dc41b1a3e1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 퇴근해 보겠습니다.\n",
            "출력 : 학교 다닐 때가 좋은 거예요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'학교 다닐 때가 좋은 거예요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "sentence_generation('퇴근해 보겠습니다.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "bQVrNpc8Gec0",
        "outputId": "390e5510-52f6-4742-a4de-664b11d0748b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 추석 연휴 잘 지내시기 바랍니다!\n",
            "출력 : 썸은 짧은 게 좋습니다 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'썸은 짧은 게 좋습니다 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "sentence_generation('추석 연휴 잘 지내시기 바랍니다!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "HsEg-PoRGei8",
        "outputId": "d03afcb1-b960-4d11-83f0-9116127f0a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 오늘은 뭐 할 거예요?\n",
            "출력 : 그건 절대 아닐 거예요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'그건 절대 아닐 거예요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "sentence_generation('오늘은 뭐 할 거예요?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "N6h9WQcnGepY",
        "outputId": "ccced6a3-8be3-4efb-b6f4-f777a5ab0e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 아 오늘 버스 퍼져서 지각한거 킹받네!!\n",
            "출력 : 다음에는 픽서를 사용해보세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'다음에는 픽서를 사용해보세요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 183
        }
      ],
      "source": [
        "# 이거 알아들은 거 조금 신선한 충격!!!\n",
        "sentence_generation('아 오늘 버스 퍼져서 지각한거 킹받네!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "uy2mXfjQGevq",
        "outputId": "f8ea0e21-b63d-491e-f7c6-4f7f1f358d4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 맛점하세요!\n",
            "출력 : 축하합니다 !\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'축하합니다 !'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "sentence_generation('맛점하세요!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "JW0CB85UGe07",
        "outputId": "8975bf66-e42b-476e-e8c6-1e34570feb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 방가방가, 방학 잘 보냄?\n",
            "출력 : 기분이 조금이나마 나아졌길 바랍니다 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'기분이 조금이나마 나아졌길 바랍니다 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "sentence_generation('방가방가, 방학 잘 보냄?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ius3hGPzGe5P",
        "outputId": "faaada8a-f05d-48b9-91b0-bad52e87a920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 : 니 여친 완죤 존예네!\n",
            "출력 : 자신을 우선순위로 해주세요 .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'자신을 우선순위로 해주세요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 186
        }
      ],
      "source": [
        "sentence_generation('니 여친 완죤 존예네!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHZVQbTFaK5h"
      },
      "source": [
        "# ✍ 결과 분석\n",
        "\n",
        "<1차>   \n",
        "D_MODEL = 256  \n",
        "NUM_LAYERS = 2  \n",
        "NUM_HEADS = 8  \n",
        "UNITS = 512  \n",
        "DROPOUT = 0.1  \n",
        "EPOCHS = 30  \n",
        "\n",
        "|순번|Q|A|\n",
        "|:------|:------|:------:|\n",
        "|1| 식사 맛있게 하세요!|당신 그대로의 모습이 보기 좋아요 .|\n",
        "|2| 취미가 뭐예요?|일 핑계로 연락해봐요 .|\n",
        "|3| 오늘은 왜 결석했나요?|그럴 수도 있어요 .|\n",
        "|4| 퇴근해 보겠습니다.|째깍 .|\n",
        "|5| 추석 연휴 잘 지내시기 바랍니다!|시간적 여유가 생겨서 그런가봐요 .|\n",
        "|6| 오늘은 뭐 할 거예요?|그건 좀 힘들 때 도와주세요 .|\n",
        "|7| 아 오늘 버스 퍼져서 지각한거 킹받네!!|시간은 핑계예요 .|\n",
        "|8| 맛점하세요!|모든 일이 뜻대로 흘러가진 않나봐요 .|\n",
        "|9| 방가방가, 방학 잘 보냄?|핸드폰은 핸드폰 가게에서 바꾸세요 .|\n",
        "|10| 니 여친 완죤 존예네!|대화를 이유가 없다면 서운함을 전해보세요 .|\n",
        "\n",
        "* 순번 7번의 Q&A의 경우 화가 났다는 뜻의 약간 신조어 격인 킹받다라는 단어를 썼는데, 이게 알아들은 건지 '시간은 핑계예요'라는 그럴 듯한 답변이 나와서 제법 놀랐다!!\n",
        "* 그러나 나머지의 경우는 약간 문맥상 적절한 답안이 나오지는 못한 것 같아서 아쉬웠다!!\n",
        "\n",
        "\n",
        "<2차>   \n",
        "D_MODEL = 256  \n",
        "NUM_LAYERS = 2  \n",
        "NUM_HEADS = 8  \n",
        "UNITS = 256  \n",
        "DROPOUT = 0.1  \n",
        "EPOCHS = 50 \n",
        "\n",
        "|순번|Q|A|\n",
        "|:------|:------|:------:|\n",
        "|1| 식사 맛있게 하세요!|그래도 상관없어요 . 칭찬해주고 싶네요 .|\n",
        "|2| 취미가 뭐예요?|그래도 취미 생활이 있어야 사는 재미가 있죠 .|\n",
        "|3| 오늘은 왜 결석했나요?|최선을 다한 건 좋은 거예요 .|\n",
        "|4| 퇴근해 보겠습니다.|째깍째깍 .|\n",
        "|5| 추석 연휴 잘 지내시기 바랍니다!|썸 타기 좋은 계절이에요 .|\n",
        "|6| 오늘은 뭐 할 거예요?|그건 절대 아닐 거예요 .|\n",
        "|7| 아 오늘 버스 퍼져서 지각한거 킹받네!!|의미심장한 메세지가 어떨까요 .|\n",
        "|8| 맛점하세요!|좋아요 !|\n",
        "|9| 방가방가, 방학 잘 보냄?|맛있는 거 드세요 .|\n",
        "|10| 니 여친 완죤 존예네!|축하드려요 !|\n",
        "\n",
        "* 다른 건 별로 안 건드리고 1차 때보다 에포크만 조금 더 줘 봤는데 아까보다는 확실히 문맥이 통하는 Q&A 세트가 좀 나온 거 같았다.\n",
        "* 특히 8번의 '맛점하세요'랑 10번 '니 여친 완죤 존예네!' 처럼 요새 사람들이 자주 쓰는 줄임말로 표현했는데도 제법 적절한 답이 툭 튀어나온 거 같아서 나름 뿌듯했다. 시간이 없어서 에포크를 더 못 늘려 보겠지만 에포크를 늘린 게 조금은 학습에 도움이 되는 걸 느낄 수 있었다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr99p8V1l8_V"
      },
      "source": [
        "# ✍  루브릭\n",
        "|평가문항|상세기준|결과체크|\n",
        "|:------|:------:|------:|\n",
        "|1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.|공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|○|\n",
        "|2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|○|\n",
        "|3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.|한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다.|○|\n",
        "\n",
        "그냥 하나라도 맥락에 맞는 한국어 답변을 리턴했다고 보고 1번, 2번, 3번 전 항목에 대해 다 ○를 주었다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_TevXDl40sH"
      },
      "source": [
        "# ✍ 회고\n",
        "\n",
        "* 일단 이번 노드의 경우는 개념 자체가 범접할 수 없는 난이도였던 거 같다!! 그래도 나름 재미있는 노드라는 생각이 들었다!!\n",
        "\n",
        "* 왜냐하면 챗봇을 만들기 위한 모델 구현 과정부터 챗봇이 맥락상 적절한 답변을 하도록 평가하고 수정하는 과정까지 굉장히 많은 과정을 밟아왔기 때문인데, 하고 나서 느낀 점은 이 어려운 과정을 해냈다고 생각하니 나 자신이 너무 대견하고 뿌듯하다는 것이다!! CV를 하기로 결심했음에도 NLP 쪽에서 이런 다양한 시도를 해 볼 수 있다는 게 어디 쉬운 결심인가!!!\n",
        "\n",
        "* 모델을 설계하고 입력값(질문 문장)을 다양하게 줘 봤다. 심지어 존예라든지 맛점이라든지 킹받는다든지... 이런 요새 사람들이 자주 쓰는 준말이나 신조어도 입력을 해 봤다는 것이다. 이런 시도 자체를 해 봤다는 게 다시 생각해 봐도 대단한 거 같다. 심지어 적절한 답변이 제대로 나온 것도 몇 개 존재했던 거 같아서 더 그런 느낌이 들었는지도 ㅎㅎ.\n",
        "\n",
        "* EPOCH는 시간상 50회까지만 돌려보는 데 그쳤지만 모델 설계의 기본 뼈대를 알았기 때문에 CV를 가게 되더라도 모델 설계를 함에 있어 하이퍼 파라미터를 어떻게 조작하면 될지를 이제 조금을 알 수 있게 되지 않았나 하며 이번 노드도 무사히 완료!!!\n",
        "\n",
        "대화형 챗봇 참조 블로그 링크 : \n",
        "https://wikidocs.net/89786"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}